# AI搭載リアルタイム議事録作成アプリケーション

Web Speech APIとGoogle Gemini APIを活用した、リアルタイム音声認識・AI要約・話者識別機能を搭載した包括的な議事録作成Webアプリケーションです。

## 主要機能

### 🤖 AI機能（Gemini API統合）
- **AI要約**: 会議内容の自動要約生成
- **話者識別**: 複数話者の自動識別と分類
- **トークン管理**: 使用量トラッキングとレート制限管理

### 🎤 音声認識・変換
- **リアルタイム音声認識**: Web Speech APIによる連続音声認識（日本語対応）
- **音声合成**: 認識テキストからの音声読み上げ機能
- **ライブ文字起こし**: リアルタイム表示対応

### 📊 可視化・管理
- **タイムライン表示**: 話者別発言の時系列可視化
- **履歴管理**: セッション保存・検索機能
- **インライン編集**: タイムライン上での直接編集

### 💾 データ管理
- **エクスポート**: JSON形式（話者情報付き）・TXT形式
- **インポート**: 過去セッションの読み込み
- **構造化データ**: 話者・発言・タイムスタンプの完全な記録

## セットアップ

### 必要要件
- **Gemini APIキー**: [Google AI Studio](https://aistudio.google.com/app/apikey)から取得
- **推奨ブラウザ**: Chrome/Chromiumベース（Web Speech API最適化）
- **マイクアクセス**: 音声認識機能に必須
- **HTTPS**: 本番環境でのマイクアクセスに必要

### ローカル開発
```bash
# ローカル開発サーバーを開始
npm run serve

# アクセス
# AI議事録アプリ: http://localhost:3000/minutes/
```

### Gemini API設定
1. アプリケーションを開く
2. 画面上部の「gemini-api-key」フィールドにAPIキーを入力
3. 「APIキー確認」ボタンをクリックして検証
4. 使用するモデルを選択（デフォルト: gemini-2.5-flash）

## 使用方法

### 基本フロー
1. **APIキー設定**: Gemini APIキーを入力・検証
2. **音声認識開始**: 「音声認識を開始」ボタンをクリック
3. **リアルタイム文字起こし**: 発言が自動的にテキスト化
4. **AI分析**:
   - 「テキストを要約」: 会議内容の要約を生成
   - 「話者を識別」: 話者を自動識別してタイムライン表示
5. **保存・エクスポート**:
   - 「履歴に保存」: ローカルストレージに保存
   - 「PCに保存」: JSON/TXT形式でダウンロード

### タイムライン機能
- 話者識別後、右側にタイムライン表示
- 各発言は話者ごとに色分け
- 発言をクリックして直接編集可能
- ゴミ箱アイコンで発言を削除

## アーキテクチャ

### ディレクトリ構成

```
/
├── minutes/                        # AI議事録アプリケーション
│   ├── index.html                  # メインHTML
│   ├── css/
│   │   ├── style.css               # 統一スタイルシート
│   │   └── history.css             # 履歴・タイムラインスタイル
│   ├── js/
│   │   ├── main.js                 # メインアプリケーションクラス
│   │   ├── geminiManager.js        # Gemini API管理
│   │   ├── speechRecognition.js    # 音声認識管理
│   │   ├── textToSpeech.js         # 音声合成管理
│   │   ├── timelineRenderer.js     # タイムライン描画
│   │   ├── uiManager.js            # UI状態管理
│   │   ├── tabManager.js           # タブ・履歴管理
│   │   ├── domElements.js          # DOM要素管理
│   │   ├── debugLogger.js          # デバッグログ機能
│   │   ├── vibeLogger.js           # AI用構造化ログ
│   │   └── debugUI.js              # リアルタイムデバッグUI
│   └── speak.js                    # 音声合成ユーティリティ
│
├── docs/                           # ドキュメント
├── README.md                       # プロジェクトREADME
├── CLAUDE.md                       # 開発ガイド
├── DEBUG.md                        # デバッグガイド
└── package.json                    # 依存関係管理
```

### 主要コンポーネント

**AI・音声認識:**
- `geminiManager.js`: Gemini API管理（要約・話者識別・トークン管理）
- `speechRecognition.js`: Web Speech API音声認識
- `textToSpeech.js`: 音声合成管理

**UI・可視化:**
- `timelineRenderer.js`: タイムライン描画・編集
- `uiManager.js`: UI状態管理
- `tabManager.js`: タブ・履歴管理
- `domElements.js`: DOM要素アクセス管理

**デバッグ・ログ:**
- `debugLogger.js`: メインデバッグログ機能
- `vibeLogger.js`: AIコードエージェント用構造化ログ
- `debugUI.js`: リアルタイムデバッグUI

## データフォーマット

### JSON形式（エクスポート）
```json
{
  "timestamp": "2024-12-04T12:30:00.000Z",
  "originalText": "会議の全文テキスト",
  "summary": "AI生成の要約文",
  "utterances": [
    {
      "name": "話者A",
      "text": "発言内容"
    },
    {
      "name": "話者B",
      "text": "発言内容"
    }
  ]
}
```

### TXT形式（エクスポート）
```
会議の全文テキスト（プレーンテキスト）
```

## 技術仕様

### 依存関係
- **@google/genai** ^1.25.0: Gemini API統合（ESM CDN経由）
- **vibelogger** ^0.1.0: AI可読構造化ログ
- **Web Speech API**: 音声認識（ブラウザ標準）
- **Speech Synthesis API**: 音声合成（ブラウザ標準）

### Geminiモデル対応
- `gemini-2.5-flash` (デフォルト): RPM 10, TPM 250K, RPD 1000
- `gemini-2.0-flash`: RPM 15, TPM 1M, RPD 1500
- `gemini-2.5-pro`: 高精度モデル
- カスタムモデル対応

### パフォーマンス
- リアルタイム音声認識: 低遅延処理
- AI要約: 数秒～十数秒（テキスト量による）
- 話者識別: 数秒～十数秒（発言数による）
- デバッグログ: 最小限のパフォーマンス影響

## 開発・デバッグ

### デバッグシステム

#### vibelogger統合
- **構造化ログ**: AIコードエージェント用の高度なログ機能
- **出力形式**: JSON/CSV/TXT形式で `./logs/` ディレクトリに出力
- **リアルタイム監視**: デバッグUIでのライブモニタリング

#### ログレベル
- **ERROR/WARN/INFO/DEBUG/TRACE**: 5段階のログレベル
- **開発時**: DEBUGレベル推奨
- **本番前**: INFOレベルに設定

#### デバッグ機能有効化
```
# URLパラメータでデバッグモードを有効化
?debug=DEBUG&debugUI=true

# デバッグキーボードショートカット
Ctrl+D: デバッグパネル切り替え
```

### 開発ワークフロー
1. **機能設計**: モジュール単位での機能設計
2. **実装**: 対応するクラス・モジュールでの実装
3. **デバッグ**: vibeloggerとデバッグUIでの動作確認
4. **統合テスト**: 全体フローでの動作検証

### 推奨事項
- デバッグ時は必ずvibeloggerを使用
- パフォーマンス監視（特にGemini API呼び出し時）
- 開発中はデバッグUIを有効化
- モジュール単位での機能分割を維持

## 処理フロー
![6656565-1](https://github.com/user-attachments/assets/49fac104-e658-44c6-a52c-0db5e0cc4c47)

## デプロイメント

**本番デプロイ:**
- Git → GitHub Actions → さくらサーバー（自動デプロイ）
- **重要**: WinSCPでの直接アップロードは禁止
- GitHubリポジトリ経由での自動デプロイを必須とする

## バージョン情報

### 現在のバージョン
**AI議事録アプリケーション** (`/minutes/`)
- Gemini API統合（AI要約・話者識別）
- リアルタイム音声認識（日本語対応）
- タイムライン可視化・インライン編集
- 構造化データエクスポート（JSON/TXT）
- 履歴管理・検索機能
- デバッグシステム統合（vibelogger）

### 更新履歴
- **2025-12-18**: レガシー機能（kuromoji.js含む）を削除、メイン機能に統合完了

## 🔄 引き継ぎ者向け（今後の開発課題）

このセクションは、来年度以降にこのプロジェクトを引き継ぐ方向けの情報です。

### 📌 利用対象者

このアプリは**特別支援学校の教員・職員**が会議の議事録作成に利用することを想定しています。
そのため、ITに詳しくないユーザーでも直感的に使えること、プライバシーへの配慮が重要です。

---

### 🚨 優先度：高 - 早期に対応してほしい課題

#### 1. Gemini API無料枠のデータ利用問題

**現状の問題:**
- 現在、Gemini APIの**無料枠**を使用しています
- 無料枠ではGoogleが**入力データをAIの学習に利用する可能性**があります
- 会議内容には生徒の個人情報やセンシティブな情報が含まれる可能性があるため、プライバシー上のリスクがあります

**改善案:**
- **有料プラン（Gemini API Paid Tier）への移行**: データが学習に使用されない
- **Google Cloud Vertex AI経由での利用**: エンタープライズ向けのデータ保護が適用される
- **ローカルLLM（Ollama等）への対応**: 完全にオフラインで処理可能（ただし精度・速度のトレードオフあり）
- 利用規約の確認: https://ai.google.dev/gemini-api/terms

#### 2. 話者識別のリアルタイム化

**現状の問題:**
- 現在は「〇〇です。」と**発言者が名前を都度言う**ことで話者を識別しています
- 会議中に毎回名前を言うのは不自然で、忘れることも多い

**改善案:**
- **声紋認識の導入**: Web Audio APIで音声特徴量を抽出し、話者を自動識別
- **事前登録方式**: 会議前に参加者の声を数秒録音して登録
- **座席・マイク位置による識別**: 複数マイク環境での位置ベース識別
- **顔認識との連携**: カメラを使った話者識別（プライバシー要検討）

参考ライブラリ:
- [pyannote.audio](https://github.com/pyannote/pyannote-audio)（Python、サーバーサイド）
- [Speaker Diarization API](https://cloud.google.com/speech-to-text/docs/multiple-voices)（Google Cloud）

#### 3. UIの改善

**現状の問題:**
- 機能が多く、初見では操作がわかりにくい
- ボタンの配置や用語がIT向けで、一般ユーザーには難しい部分がある

**改善案:**
- **チュートリアル/ガイド表示**: 初回起動時に使い方を案内
- **シンプルモード**: 基本機能のみ表示するモード追加
- **ボタン配置の整理**: 「開始」「停止」「保存」を大きく目立つ配置に
- **用語の見直し**: 「APIキー」→「接続キー」など、わかりやすい表現に
- **ステップバイステップUI**: ウィザード形式での操作案内

---

### 📋 優先度：中 - 余裕があれば対応してほしい課題

#### 4. アクセシビリティの向上

特別支援学校での利用を考慮すると、アクセシビリティは重要です：

- **フォントサイズ調整**: 文字サイズを大きくできるオプション
- **ハイコントラストモード**: 視認性の向上
- **キーボード操作**: マウスなしでも全機能が使えるように
- **スクリーンリーダー対応**: ARIA属性の適切な設定
- **音声フィードバック**: 操作完了時の音声通知

#### 5. オフライン対応

学校のネットワーク環境が不安定な場合への対策：

- **PWA化**: Service Workerによるオフラインキャッシュ
- **ローカル音声認識**: [Vosk](https://alphacephei.com/vosk/)等のオフライン音声認識エンジン
- **ローカルLLM**: Ollama + Llama等でのオフライン要約

#### 6. ブラウザ互換性の拡大

- 現在はChrome/Chromiumベースのブラウザのみ対応
- Safari、Firefox等への対応検討（Web Speech APIの制限あり）
- モバイル対応（iPad等での利用を想定）

#### 7. 音声認識精度の向上

- **専門用語辞書**: 教育用語、学校固有の用語を登録
- **ノイズキャンセル**: 教室環境でのノイズ対策
- **子どもの発言対応**: 児童生徒の発言も認識できるよう調整
- **カスタム言語モデル**: Google Cloud Speech-to-Text等のカスタムモデル

---

### 💡 その他の提案

#### セキュリティ・プライバシー関連

- **データの自動削除**: 一定期間後に保存データを自動削除するオプション
- **暗号化**: ローカルストレージのデータ暗号化
- **アクセス制限**: パスワードや認証機能の追加
- **ログ出力の制御**: デバッグログにセンシティブ情報が含まれないよう注意

#### 機能拡張

- **議事録テンプレート**: 学校で使う定型フォーマットへの対応
- **複数会議の管理**: 会議種別（職員会議、ケース会議等）での分類
- **共有機能**: 議事録を他の職員と共有する仕組み
- **印刷最適化**: 印刷用のレイアウト

---

### 📚 開発を始める前に

1. `CLAUDE.md` を熟読してください（開発ルールが記載されています）
2. `npm run serve` でローカル環境を起動
3. `http://localhost:8000/minutes/?debug=DEBUG&debugUI=true` でデバッグモードで動作確認
4. Gemini APIキーを取得して動作を体験してください

質問があれば、前任者（このプロジェクトを作成したメンバー）に連絡してください。

---

## ライセンス・クレジット

- **Web Speech API**: ブラウザ標準API
- **Google Gemini API**: Google AI
- **vibelogger**: https://github.com/fladdict/vibe-logger

---

## 開発者向け情報

詳細な開発ガイドラインについては `CLAUDE.md` を参照してください。
